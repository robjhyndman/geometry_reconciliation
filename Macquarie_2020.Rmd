---
title: "The geometry of forecast reconciliation"
author: "Rob J Hyndman"
date: 28 August 2020
fontsize: 14pt
titlefontsize: 32pt
classoption: aspectratio=169
toc: true
output:
  binb::monash:
    fig_height: 4.33
    fig_width: 7
    colortheme: monashwhite
    keep_tex: yes
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE,
  dev.args = list(pointsize = 11)
)
options(digits = 3, width = 88)
library(fpp3)
library(patchwork)
```

# Hierarchical and grouped time series

## Australian tourism
\placefig{-0.3}{1.4}{width=9.4cm, height=20cm, keepaspectratio=TRUE}{regions1_with_labels}

\only<2>{\begin{textblock}{6.4}(9.3,1.4)
\begin{block}{}
  \begin{itemize}\itemsep=0cm\parskip=0cm
    \item Monthly data on visitor night from 1998 -- 2017
    \item From \textit{National Visitor Survey}, annual interviews of 120,000 Australians aged 15+.
    \item Geographical hierarchy split by 
    \begin{itemize}
    \item 7 states
    \item 27 zones
    \item 75 regions
    \end{itemize}
  \end{itemize}
\end{block}
\end{textblock}}

## Australian tourism data
\fontsize{11}{12}\sf

```{r tourism, echo=FALSE}
# Read csv file of monthly data
OvernightTrips_Region <- readr::read_csv("OvernightTrips_2017.csv")[,-(1:3)] %>%
  # Replace outlier from Adelaide Hills
  mutate(
    `Adelaide Hills` = case_when(
      `Adelaide Hills` > 80 ~ 10,
                       TRUE ~ `Adelaide Hills`
    )
  )
# Convert to tsibble
tourism <- hts::hts(
    ts(OvernightTrips_Region, start=1998, frequency=12),
    list(7, c(6,5,4,4,3,3,2), c(2,2,1,4,4,1,3,1,3,6,7,3,4,3,2,3,3,4,2,3,1,1,1,2,2,3,4))
  ) %>%
  as_tsibble() %>%
  rename(
    state = "Level 1",
    zone = "Level 2",
    region = "Level 3",
    month = index,
    visitors = value
  ) %>%
  mutate(
    state = recode(state,
      A = "NSW",
      B = "VIC",
      C = "QLD",
      D = "SA",
      E = "WA",
      F = "TAS",
      G = "NT"
    ),
    zone = recode(zone,
      AA = "Metro NSW",
			AB = "North Coast NSW",
			AC = "South Coast NSW",
			AD = "South NSW",
			AE = "North NSW",
			AF = "ACT",
			BA = "Metro VIC",
			BB = "West Coast VIC",
			BC = "East Coast VIC",
			BC = "North East VIC",
			BD = "North West VIC",
			CA = "Metro QLD",
			CB = "Central Coast QLD",
			CC = "North Coast QLD",
			CD = "Inland QLD",
			DA = "Metro SA",
			DB = "South Coast SA",
			DC = "Inland SA",
			DD = "West Coast SA",
			EA = "West Coast WA",
			EB = "North WA",
			EC = "South WA",
			FA = "South TAS",
			FB = "North East TAS",
			FC = "North West TAS",
			GA = "North Coast NT",
			GB = "Central NT"
    )
  ) %>%
  select(month, everything())
# Show first 10 rows of data
tourism
```

## Australian tourism data


```{r tourism_plots, include=FALSE, fig.width=12, fig.height=5}
p1 <- tourism %>% 
  summarise(visitors = sum(visitors)) %>%
  autoplot(visitors) +
  ylab("Overnight trips") + xlab("Time") +
  scale_y_log10() +
  ggtitle("Total domestic travel: Australia")
p2 <- tourism %>% 
  summarise(visitors = sum(visitors)) %>%
  gg_season(visitors, labels='right') +
  ylab("Overnight trips") +
  ggtitle("Total domestic travel: Australia") +
  scale_y_log10() 
p3 <- tourism %>%
  group_by(state) %>%
  summarise(visitors = sum(visitors)) %>%
  autoplot(visitors) +
  ylab("Overnight trips") +
  scale_y_log10() +
  ggtitle("Total domestic travel: by state")
p4 <- tourism %>%
  filter(state=="NSW") %>%
  group_by(zone) %>%
  summarise(visitors = sum(visitors)) %>%
  autoplot(visitors) +
  ylab("Overnight trips") +
  scale_y_log10() +
  ggtitle("Total domestic travel: NSW by zone")
p5 <- tourism %>%
  filter(zone=="South NSW") %>%
  autoplot(visitors) +
  ylab("Overnight trips") +
  scale_y_log10() +
  ggtitle("Total domestic travel: South NSW by region")
aligned_plots <- align_patches(p1, p2, p3, p4, p5)
for(i in seq_along(aligned_plots)) {
  pdf(paste0("./figs/tourism",i,".pdf"), width=12*.8, height=5*.8)
  print(aligned_plots[[i]])
  crop::dev.off.crop()
}
```

\only<1>{\placefig{0.3}{1.7}{width=15.5cm}{tourism1}}
\only<2>{\placefig{0.3}{1.7}{width=15.5cm}{tourism2}}
\only<3>{\placefig{0.3}{1.7}{width=15.5cm}{tourism3}}
\only<4>{\placefig{0.3}{1.7}{width=15.5cm}{tourism4}}
\only<5>{\placefig{0.3}{1.7}{width=15.5cm}{tourism5}}

## Hierarchical time series

A \alert{\textbf{hierarchical time series}} is a collection of several time series that are linked together in a hierarchical structure.

\begin{center}
\begin{minipage}{9.6cm}
\begin{block}{}
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,fill=red!15]
\tikzstyle[level distance=.1cm]
\tikzstyle[sibling distance=7cm]
\tikzstyle{level 1}=[sibling distance=33mm,set style={{every node}+=[fill=blue!15]}]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AA}}
   child {node {AB}}
   child {node {AC}}
 }
 child {node {B}
   child {node {BA}}
   child {node {BB}}
   child {node {BC}}
 }
 child {node {C}
   child {node {CA}}
   child {node {CB}}
   child {node {CC}}
 };
\end{tikzpicture}
\end{block}
\end{minipage}
\end{center}

## Grouped time series

A \alert{\textbf{grouped time series}} is a collection of time series that can be grouped together in a number of non-hierarchical ways.

\vspace*{-0.2cm}\begin{center}
\begin{minipage}{9.2cm}
\begin{block}{}
\begin{tikzpicture}[level distance=1.5cm]
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,outer sep=0pt, fill=red!15]
\tikzstyle{level 1}=[sibling distance=23mm,set style={{every node}+=[fill=blue!15]},level distance=1cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}, level distance=0.9cm]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AX}}
   child {node {AY}}
 }
 child {node {B}
   child {node {BX}}
   child {node {BY}}
 };
\end{tikzpicture}\hspace*{1cm}
\begin{tikzpicture}[level distance=1.5cm]
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,outer sep=0pt, fill=red!15]
\tikzstyle{level 1}=[sibling distance=23mm,set style={{every node}+=[fill=blue!15]},level distance=1cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}, level distance=0.9cm]
\node{Total}[edge from parent fork down]
 child {node {X}
   child {node {AX}}
   child {node {BX}}
 }
 child {node {Y}
   child {node {AY}}
   child {node {BY}}
 };
\end{tikzpicture}
\end{block}
\end{minipage}
\end{center}

\pause\alert{Examples}\vspace*{-0.2cm}

 * Tourism by state and purpose of travel
 * Retail sales by product groups/sub groups, and by countries/regions

# Forecast reconciliation using projections

## The problem
\fontsize{13}{14}\sf
\begin{alertblock}{}
How to produce \textbf{coherent} forecasts at all nodes?
\end{alertblock}\pause

### Old approaches (pre 2009)

  * Bottom-up forecasting
  * Top-down forecasting
  * Middle-out forecasting

\pause

### Forecast reconcilation approach

1. Forecast all series at all levels of aggregation using an automatic forecasting algorithm.  (e.g., `ETS`, `ARIMA`, ...)
2. Reconcile the resulting forecasts so they are coherent using least squares optimization (i.e., find closest reconciled forecasts to the original forecasts).

## Key forecast reconciliation papers
\fontsize{12}{14}\sf

* Hyndman, Ahmed, Athanasopoulos, Shang (2011 \emph{CSDA}) Optimal combination forecasts for hierarchical time series.
* Athanasopoulos, Ahmed, Hyndman (2009 \emph{IJF}) Hierarchical forecasts for Australian domestic tourism.
* Hyndman, Lee, Wang (2016 \emph{CSDA}) Fast computation of reconciled forecasts for hierarchical and grouped time series.
* Wickramasuriya, Athanasopoulos, Hyndman (2019 \emph{JASA}) Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization.
* Panagiotelis, Gamakumara, Athanasopoulos, Hyndman (2020 \emph{IJF}) Forecast reconciliation: A geometric view with new insights on bias correction.
* Panagiotelis, Gamakumara, Athanasopoulos, Hyndman (2020) Probabilistic forecast reconciliation: properties, evaluation and score optimisation.


## Hierarchical and grouped time series

\begin{textblock}{8.5}(0.2,1.5)
Every collection of time series with linear constraints can be written as
\centerline{\colorbox[RGB]{210,210,210}{$\bY_{t}=\color{blue}\bS\color{red}\bm{b}_{t}$}}
\vspace*{-0.9cm}\begin{itemize}\parskip=0cm\itemsep=0cm
\item $\by_t=$ vector of all series at time $t$
\item $ y_{t}= $ aggregate of all series at time
$t$.
\item $ y_{X,t}= $ value of series $X$ at time $t$.
\item $\color{red}{\bm{b}_t}=$ vector of most disaggregated series at time $t$
\item $\color{blue}{\bS}=$ ``summing matrix'' containing the linear constraints.
\end{itemize}
\end{textblock}

\begin{textblock}{5.7}(11.4,0.1)
\begin{minipage}{4cm}
\begin{block}{}\centering
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]
\tikzstyle[level distance=.3cm]
\tikzstyle[sibling distance=12cm]
\tikzstyle{level 1}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=blue!15]}]
\node{Total}[edge from parent fork down]
 child {node {A}
 }
 child {node {B}
 }
 child {node {C}
 };
\end{tikzpicture}
\end{block}
\end{minipage}
\end{textblock}

\begin{textblock}{5.7}(9.4,2.9)\fontsize{14}{15}\sf
\begin{align*}
\bY_{t}&= \begin{pmatrix}
  y_{t}\\
  y_{A,t}\\
  y_{B,t}\\
  y_{C,t}
  \end{pmatrix}  \\
  &= {\color{blue}\underbrace{\begin{pmatrix}
                1 & 1 & 1 \\
                1 & 0 & 0 \\
                0 & 1 & 0\\
                0 & 0 & 1
                \end{pmatrix}}_{\bS}}
     {\color{red}\underbrace{\begin{pmatrix}
       y_{A,t}\\y_{B,t}\\y_{C,t}
       \end{pmatrix}}_{\bm{b}_{t}}}
\end{align*}
\end{textblock}

\vspace*{10cm}


## Hierarchical time series

\begin{block}{}\hspace*{.6cm}{\centering\small
\begin{tikzpicture}[level distance=1cm]
\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]
\tikzstyle[level distance=.01cm]
\tikzstyle[sibling distance=12cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\scriptsize,set style={{every node}+=[fill=yellow]}]
\tikzstyle{level 1}=[sibling distance=40mm,font=\footnotesize,set style={{every node}+=[fill=blue!15]}]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AX}}
   child {node {AY}}
   child {node {AZ}}
 }
 child {node {B}
   child {node {BX}}
   child {node {BY}}
   child {node {BZ}}
 }
 child {node {C}
   child {node {CX}}
   child {node {CY}}
   child {node {CZ}}
 };
\end{tikzpicture}}
\end{block}\vspace*{0.1cm}\pause\fontsize{8}{8}\sf

\hbox{$\by_{t}= \begin{pmatrix}
    y_t\\
    y_{A,t}\\
    y_{B,t}\\
    y_{C,t}\\
    y_{AX,t}\\
    y_{AY,t}\\
    y_{AZ,t}\\
    y_{BX,t}\\
    y_{BY,t}\\
    y_{BZ,t}\\
    y_{CX,t}\\
    y_{CY,t}\\
    y_{CZ,t}\end{pmatrix}=
    {\color{red}{\begin{pmatrix}
                1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
                1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
                0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0\\
                0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1\\
                1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
                0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
                0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
                0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\
                0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\
                0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
                0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
                0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\
                0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
             \end{pmatrix}}}{\color{blue}{\begin{pmatrix}
    y_{AX,t}\\
    y_{AY,t}\\
    y_{AZ,t}\\
    y_{BX,t}\\
    y_{BY,t}\\
    y_{BZ,t}\\
    y_{CX,t}\\
    y_{CY,t}\\
    y_{CZ,t}\end{pmatrix}}}$}

    \vspace*{10cm}

\only<3>{\begin{textblock}{3}(10.5,8)\fontsize{14}{15}\sf\colorbox[gray]{.8}{$\by_{t}=\color{red}\bS\color{blue}\bm{b}_{t}$}\end{textblock}}


## Grouped data

\begin{block}{}
\begin{center}\small
\tikzstyle{every node}=[inner sep=2pt]
\begin{tikzpicture}
    \matrix[ampersand replacement=\&,column sep=0.3cm] {
        \node[ellipse,draw,fill=yellow,font=\scriptsize,distance=1cm] {AX};~ \&
        \node[ellipse,draw,fill=yellow,font=\scriptsize] {AY};~ \&
        \node[ellipse,draw,fill=blue!15] {A}; \\[0.3cm]
        \node[ellipse,draw,fill=yellow,font=\scriptsize] {BX};~ \&
        \node[ellipse,draw,fill=yellow,font=\scriptsize] {BY};~ \&
        \node[ellipse,draw,fill=blue!15] {B}; \\[0.3cm]
        \node[ellipse,draw,fill=blue!15] {X};~ \&
        \node[ellipse,draw,fill=blue!15] {Y};~ \&
        \node[ellipse,draw,fill=red!15] {Total}; \\
};
\end{tikzpicture}
\end{center}
\end{block}\pause\fontsize{10}{11}\sf


\hbox{$\by_{t}= \begin{pmatrix}
    y_t\\
    y_{A,t}\\
    y_{B,t}\\
    y_{X,t}\\
    y_{Y,t}\\
    y_{AX,t}\\
    y_{AY,t}\\
    y_{BX,t}\\
    y_{BY,t}
    \end{pmatrix}=
    \color{red}\begin{pmatrix}
                1 & 1 & 1 & 1 \\
                1 & 1 & 0 & 0 \\
                0 & 0 & 1 & 1 \\
                1 & 0 & 1 & 0 \\
                0 & 1 & 0 & 1 \\
                1 & 0 & 0 & 0 \\
                0 & 1 & 0 & 0 \\
                0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 1
             \end{pmatrix}
    \color{blue}\begin{pmatrix}
    y_{AX,t}\\
    y_{AY,t}\\
    y_{BX,t}\\
    y_{BY,t}
    \end{pmatrix}$}

\vspace*{-1cm}

\only<3>{\begin{textblock}{3}(10.5,8)\fontsize{14}{15}\sf\colorbox[gray]{.8}{$\by_{t}=\color{red}\bS\color{blue}\bm{b}_{t}$}\end{textblock}}

\vspace*{10cm}

## Definitions

\begin{textblock}{9}(.2,1.25)\fontsize{13}{14}\sf
\begin{block}{Coherent subspace}
$m$-dimensional linear subspace $\mathfrak{s}\subset \mathbb{R}^n$ for which linear constraints hold for all $\bm{y}\in\mathfrak{s}$.
\end{block}\vspace*{-0.25cm}
\begin{block}{Hierarchical time series}
An $n$-dimensional multivariate time series such that $\bm{y}_t\in\mathfrak{s}\quad\forall t$.
\end{block}\vspace*{-0.25cm}
\begin{block}{Coherent point forecasts}
$\tilde{\bm{y}}_{t+h|t}$ is \emph{coherent} if $\tilde{\bm{y}}_{t+h|t} \in \mathfrak{s}$.
\end{block}\vspace*{-0.2cm}
\end{textblock}
\only<2-3>{\begin{textblock}{7.5}(.2,6.6)
\begin{alertblock}{Base forecasts}
Let $\hat{\bm{y}}_{t+h|t}$ be vector of \emph{incoherent} initial $h$-step forecasts.$\phantom{y_{t|h}}$
\end{alertblock}
\end{textblock}}
\only<3>{\begin{textblock}{7.5}(8.3,6.6)
\begin{alertblock}{Reconciled forecasts}
Let $\psi$ be a mapping, $\psi:\mathbb{R}^n\rightarrow\mathfrak{s}$.  $\tilde{\bm{y}}_{t+h|t}=\psi(\hat{\bm{y}}_{t+h|t})$ ``reconciles'' $\hat{\bm{y}}_{t+h|t}$.
\end{alertblock}
\end{textblock}}

\placefig{9.4}{.0}{width=6.6cm}{3D_hierarchy}
\begin{textblock}{3}(11.4,5.6)
\begin{block}{}
\centerline{$ y_{Tot} = y_A + y_B$}
\end{block}
\end{textblock}

## Linear reconciliation

\begin{textblock}{9}(0.2,1.25)\fontsize{13}{14}\sf
\begin{alertblock}{}
If $\psi$ is a linear function and $\bm{G}$ is some matrix, then
$$\tilde{\bm{y}}_{t+h|t}=\bm{S}\bm{G}\hat{\bm{y}}_{t+h|t}$$
\end{alertblock}\vspace*{-0.4cm}
\begin{itemize}
\item $\bm{G}$ extracts and combines base forecasts $\hat{\by}_{T+h|T}$ to get bottom-level forecasts.
\item $\bS$ creates linear combinations.
\item e.g., OLS reconciliation: $\bm{G} = (\bm{S}'\bm{S})^{-1}\bm{S}'$
\end{itemize}
\end{textblock}

\only<2->{
\placefig{9.4}{-0.5}{width=6.6cm}{fig3}
}

\only<3>{
  \begin{textblock}{9}(0.2,6.)
  \begin{block}{Projections}
  Suppose $\bm{S}\bm{G}$ is a projection onto $\mathfrak{s}$, then\fontsize{12}{13}\sf
  \begin{itemize}
  \item Coherent base forecasts are unchanged.
  \item Unbiased base forecasts remain unbiased.
  \end{itemize}
  \end{block}
  \end{textblock}
}
\only<3>{
  \begin{textblock}{6.6}(9.2,6.5)\fontsize{12}{12}\sf
  \begin{itemize}
  \item Orthogonal projections lead to smallest possible adjustments of base forecasts.
  \end{itemize}
  \end{textblock}
}

\only<4>{
  \begin{textblock}{9}(0.2,6)
  \begin{block}{Distance reducing property}
  If $\bm{S}\bm{G}$ is an orthogonal projection onto $\mathfrak{s}$ then:
  \begin{equation*}
    \|\bm{y}_{t+h}-\tilde{\bm{y}}_{t+h|t}\|\le\|\bm{y}_{t+h}-\hat{\bm{y}}_{t+h|t}\|.
  \end{equation*}
  \end{block}
  \end{textblock}
}

\only<4>{
  \begin{textblock}{6.6}(9.2,5.5)\fontsize{12}{12}\sf
  \begin{itemize}
  \item Distance reduction holds for any realisation and any forecast.
  \item Other measures of forecast accuracy may be worse.
  \item Not necessarily the optimal reconciliation.
  \end{itemize}
  \end{textblock}
}

## Linear projections

\begin{textblock}{5}(6,0)
\begin{block}{}
\centerline{$\tilde{\by}_{T+h|T}=\bS\bm{G}\hat{\by}_{T+h|T}$}
\end{block}
\end{textblock}

\begin{textblock}{9}(0.2,1.25)\fontsize{13}{14}\sf
\begin{block}{Variance}
\centerline{$\bm{V}_h = \var[\by_{T+h} - \tilde{\by}_{T+h|T}  \mid \by_1,\dots,\by_n]  = \bS\bm{G}\bm{W}_{h}\bm{G}'\bS'$}
where $\bm{W}_h = \var[\by_{T+h} - \hat{\by}_{T+h|T} \mid \by_1,\dots,\by_n]$.
\end{block}\vspace*{-0.2cm}
\begin{alertblock}{Minimum trace (MinT) reconciliation}
If $\bm{S}\bm{G}$ is a projection, then the trace of $\bm{V}_h$ is minimized when
$$
  \bm{G} = (\bS'\bm{W}_h^{-1}\bS)^{-1}\bS'\bm{W}_h^{-1}{h}
$$
\end{alertblock}
\end{textblock}

\only<2>{\placefig{9.7}{1.5}{width=6.2cm}{InsampDir_1_George}}
\only<3>{\placefig{9.7}{1.5}{width=6.2cm}{InsampDir_2_George}}
\only<4>{\placefig{9.7}{1.5}{width=6.2cm}{OrthProj_George}}
\only<5>{\placefig{9.7}{1.5}{width=6.2cm}{ObliqProj_George}}

\only<2->{
  \begin{textblock}{9}(.7,6)
  \begin{itemize}\itemsep=0cm
  \item $R$ is the most likely direction of deviations from $\mathfrak{s}$.
  \only<2>{\item Orange: in-sample errors}
  \only<3->{\item Grey: potential base forecasts}
  \only<4->{\item Red: reconciled forecsts}
  \end{itemize}
  \end{textblock}
}

\only<4->{
  \begin{textblock}{5}(10,7.6)
  \begin{block}{}
  \only<4>{Orthogonal projection}
  \only<5>{Oblique projection}
  \end{block}
  \end{textblock}
}

## Linear projections

\begin{textblock}{5}(6,0)
\begin{block}{}
\centerline{$\tilde{\by}_{T+h|T}=\bS\bm{G}\hat{\by}_{T+h|T}$}
\end{block}
\end{textblock}

\begin{textblock}{9.4}(.5,1.2)
\begin{alertblock}{Reconciliation method \hspace*{0.5cm} $\bm{G}$}
\begin{tabular}{ll}
  OLS             & $(\bm{S}'\bm{S})^{-1}\bm{S}'$ \\
  WLS             & $(\bm{S}'\bm{\Lambda}\bm{S})^{-1}\bm{S}'\bm{\Lambda}$ \\
  MinT(Sample)    & $(\bm{S}'\hat{\bm{W}}_{\text{sam}}^{-1}\bm{S})^{-1}\bm{S}' \hat{\bm{W}}_{\text{sam}}^{-1}$  \\
  MinT(Shrink)\hspace*{2cm}    & $(\bm{S}'\hat{\bm{W}}_{\text{shr}}^{-1}\bm{S})^{-1}\bm{S}' \hat{\bm{W}}_{\text{shr}}^{-1}$  \\
\end{tabular}
\end{alertblock}
\end{textblock}
\begin{textblock}{14}(.2,5.1)\fontsize{13}{15}\sf
\begin{itemize}
\item $\bm{\Lambda}$ is diagonal matrix
\item $\hat{\bm{W}}_{\text{sam}}$ is sample estimate of the residual covariance matrix
\item $\hat{\bm{W}}_{\text{shr}}$ is shrinkage estimator $\tau \text{diag}(\hat{\bm{W}}_{\text{sam}})+(1-\tau)\hat{\bm{W}}_{\text{sam}}$ where $\tau = \displaystyle\frac{\sum_{i \neq j}\hat{\var}(\hat{\sigma}_{ij})}{\sum_{i \neq j}{\hat{\sigma}}^2_{ij}}$ and $\sigma_{ij}$ denotes the $(i,j)$th element of $\hat{\bm{W}}_{\text{sam}}$.
\end{itemize}
\end{textblock}

\begin{textblock}{5}(10.3,3.35)
\begin{block}{}
These approximate MinT by assuming $\bm{W}_h = k_h \bm{W}_1$.
\end{block}
\end{textblock}


# Probabilistic forecast reconciliation

## Coherent probabilistic forecasts
\begin{textblock}{9.5}(0.2,1.2)\fontsize{13}{15}\sf
\begin{block}{Coherent probabilistic forecasts}
Given the triple $(\mathbb{R}^m, \mathscr{F}_{\mathbb{R}^m}, \nu)$, a coherent probability triple $(\mathfrak{s}, \mathscr{F}_{\mathfrak{s}}, \breve{\nu})$  is such that
$$
  \breve{\nu}(s(\mathcal{B})) = \nu(\mathcal{B}) \quad \forall \mathcal{B} \in \mathscr{F}_{\mathbb{R}^m}.
$$
\end{block}\vspace*{-0.2cm}
\begin{block}{Probabilistic forecast reconciliation}
The reconciled probability measure of $\hat{\nu}$ wrt $\psi(.)$ is such that
  \[
  \tilde{\nu}(\mathcal{B}) = \hat{\nu}(\psi^{-1}(\mathcal{B})) \qquad \forall \mathcal{B} \in \mathscr{F}_{\mathfrak{s}}\,,
  \]
  where $\psi^{-1}(\mathcal{B}):=\{{\bm{y}}\in \mathbb{R}^n:\psi({\bm{y}})\in \mathcal{B}\}$ is the pre-image of $\mathcal{B}$, that is the set of all points in $\mathbb{R}^n$ that $\psi(.)$ maps to a point in $\mathcal{B}$.
\end{block}
\end{textblock}
\begin{textblock}{7}(9.5,1.2)
\resizebox{\textwidth}{!}{
\input figs/probforerec_schematic.tex
}
\end{textblock}

## Construction of reconciled distributions

\begin{block}{Reconciled density of bottom-level}
Density of bottom-level series under reconciled distribution is
$$
  \tilde{f}_{\bm{b}}(\bm{b})=|\bm{G}^*|\int \hat{f}(\bm{G}^{-}\bm{b}+\bm{G}_\perp \bm{a})d\bm{a}
$$
\vspace*{-0.5cm}\begin{itemize}
\item $\hat{f}$ is density of incoherent base probabilistic forecast
\item $\bm{G^-}$ is $n\times m$ generalised inverse of $\bm{G}$ st $\bm{G}\bm{G}^-=\bm{I}$
\item $\bm{G_\perp}$ is $n\times (n-m)$ orthogonal complement to $\bm{G}$ st $\bm{G}\bm{G}_\perp=\bm{0}$
\item $\bm{G}^*=\left(\bm{G}^-\,\vdots\,\bm{G}_\perp\right)$, and $\bm{b}$ and $\bm{a}$ are obtained via\newline the change of variables $\bm{y}=\bm{G}^*\begin{pmatrix}\bm{b}\\\bm{a}\end{pmatrix}$
\end{itemize}
\end{block}
\vspace*{10cm}

## Construction of reconciled distributions

\begin{block}{Reconciled density of full hierarchy}\fontsize{14}{15}\sf
Density of full hierarchy under reconciled distribution is
$$
  \tilde{f}_{\bm{y}}(\bm{y}) =
  |\bm{S}^*| \tilde{f}_{\bm{b}}({\bm{S}^-\bm{y}})
  \mathbb{1}\{\bm{y}\in\mathfrak{s}\}
$$
\vspace*{-0.5cm}\begin{itemize}
\item $\bm{S}^*=\begin{pmatrix}
  \bm{S}^-\\
  \bm{S}'_\perp
  \end{pmatrix}$
\item $\bm{S^-}$ is $m\times n$ generalised inverse of $\bm{S}$ such that $\bm{S}^-\bm{S}=\bm{I}$,
\item $\bm{S_\perp}$ is $n\times (n-m)$ orthogonal complement to $\bm{S}$ such that $\bm{S}'_\perp\bm{S}=\bm{0}$.
\end{itemize}
\end{block}\pause

\begin{alertblock}{Gaussian reconciliation}
If the incoherent base forecasts are $\text{N}(\hat{\bm{\mu}}, \hat{\bm{\Sigma}})$,\newline
then the reconciled density is $\text{N}(\bm{S}\bm{G}\hat{\bm{\mu}}, \bm{S}\bm{G}\hat{\bm{\Sigma}}\bm{G}'\bm{S}')$.
\end{alertblock}

## Simulation from a reconciled distribution

\begin{block}{}
Suppose that $\left(\hat{\bm{y}}^{[1]},\ldots,\hat{\bm{y}}^{[L]}\right)$ is a sample drawn from an incoherent probability measure $\hat{\nu}$. Then $\left(\tilde{\bm{y}}^{[1]},\ldots,\tilde{\bm{y}}^{[L]}\right)$ where $\tilde{\bm{y}}^{[\ell]}:=\psi(\hat{\bm{y}}^{[\ell]})$ for $\ell=1,\ldots,L$, is a sample drawn from the reconciled probability measure $\tilde{\nu}$.
\end{block}

* So reconciling sample paths from incoherent distributions works.

\vspace*{10cm}

# Evaluating probabilistic forecasts

## Evaluating probabilistic forecasts

```{r setup_tourism_example, include=FALSE}
library(gganimate)
set.seed(2020 - 08 - 25)

# Total Australian tourism numbers
aus_tourism <- tourism %>%
  summarise(visitors = sum(visitors))
# Training data
train <- aus_tourism %>%
  filter(year(month) <= 2016)
# Fit ETS model
fit <- train %>%
  model(arima = ARIMA(visitors))
# Future sample paths
future <- fit %>%
  generate(times = 200, h = "1 year") %>%
  as_tibble() %>%
  mutate(modrep = paste0(.model, .rep))
# Deciles
qf <- fit %>%
  generate(times = 1000, h = "1 year") %>%
  as_tibble() %>%
  group_by(month) %>%
  summarise(
    qs = quantile(.sim, seq(from = 0.1, to = 0.9, by = 0.1)),
    prob = seq(from = 0.1, to = 0.9, by = 0.1)
  )
# Colors of sample paths
colours <- tibble(modrep = unique(future$modrep)) %>%
  mutate(col = sample(rainbow(200)))
future <- future %>% left_join(colours, by = "modrep")

# Plot of deciles
p1 <- train %>%
  autoplot(visitors) +
  labs(
    x = "Month",
    y = "Total visitors",
    title = "Australian domestic tourism"
  ) +
  guides(colour = FALSE, level = FALSE) +
  ylim(min(train$visitors, future$.sim, na.rm = TRUE), max(train$visitors, future$.sim, na.rm = TRUE))
```


```{r tourism_data_again, fig.width=10, fig.height=5}
p1 
```

## Evaluating probabilistic forecasts

```{r eval2, fig.width=10, fig.height=5}
p1 <- p1 +
  annotate("label", x=as.Date("2017-06-01"), y=6000, label="ARIMA futures", col='#888888')
p1 +
  geom_line(
    data = filter(future, as.numeric(.rep) <= 5),
    aes(y = .sim, group = modrep, col=col),
  )
```

## Evaluating probabilistic forecasts

```{r eval3, fig.width=10, fig.height=5}
# Less data shown
p1$data <- train %>% filter(year(month) >= 2015)
p1 +
  geom_line(
    data = filter(future, as.numeric(.rep) <= 5),
    aes(y = .sim, group = modrep, col=col),
  )
```

## Evaluating probabilistic forecasts

```{r eval4, fig.width=10, fig.height=5}
p1 +
  geom_line(
    data = future,
    aes(y = .sim, group = modrep, col=col),
  )
```

## Evaluating probabilistic forecasts

```{r eval5, fig.width=10, fig.height=5}
p1 <- p1 +
  geom_line(
    data = future,
    aes(y = .sim, group = modrep),
    color = "gray"
  )
p1
```

## Evaluating probabilistic forecasts

```{r eval6, fig.width=10, fig.height=5}
p1 <- p1 +
  geom_line(
    data = qf,
    mapping = aes(x = month, y = qs, group = prob),
    colour = "#0063A7"
  ) +
  annotate("label", x=as.Date("2017-06-01"), y=11300, label="Deciles", col="#0063A7")
p1
```


## Evaluating probabilistic forecasts

```{r eval7, fig.width=10, fig.height=5}
p1 <- p1 +
  geom_line(aes(y = visitors), data = aus_tourism %>% filter(year(month) >= 2015)) 
p1
pdf("./figs/deciles.pdf", height=5, width=10)
p1
crop::dev.off.crop()
```


## Evaluating probabilistic forecasts

```{r pinball, eval=FALSE, echo=FALSE, fig.show='animate', interval=1/10, message=FALSE, fig.height=3, fig.width=5.5}
# Set eval=TRUE to generate the plots
# Then set eval=FALSE as we only need to do this once.
library(gganimate)
prob <- seq(0.05, 0.95, by = 0.05)
df <- expand.grid(
    error = c(-10, 0, 10),
    p = c(prob, rev(head(prob, -1)[-1]))
  ) %>%
  mutate(
    state = rep(seq(length(p) / 3), rep(3, length(p) / 3)),
    qpt = 2 * p * error * (error > 0) - 2 * (1 - p) * error * (error < 0)
  )
labels <- df %>%
  select(p, state) %>%
  distinct() %>%
  mutate(label = paste0("p = ", sprintf("%.2f", p)))
df %>% ggplot(aes(x = error, y = qpt)) +
  geom_line(aes(group = state), colour = "red") +
  labs(
    x = latex2exp::TeX("Error: $y_t - q_{p,t}$"),
    y = latex2exp::TeX("S_{t}(p,y)")
  ) +
  geom_label(data = labels, aes(x = 0, y = 17, label = label)) +
  transition_states(state)
```

\fontsize{12}{13}\sf
\begin{textblock}{8}(0.2,1.2)
\begin{alertblock}{}\vspace*{-0.3cm}
\begin{align*}
q_{p,t} &= \text{quantile forecast with prob. $p$ at time $t$.}\\
y_{t} &= \text{observation at time $t$}
\end{align*}
\end{alertblock}\vspace*{-0.3cm}
\begin{block}{Quantile score}\vspace*{-0.1cm}
$$
  S_t(p,y) = \begin{cases}
  2(1 - p) \big|y_t - q_{p,t}\big|, & \text{if $y_{t} < q_{p,t}$}\\
  2p \big|y_{t} - q_{p,t}\big|, & \text{if $y_{t} \ge q_{p,t}$} \end{cases}
$$
\end{block}
\end{textblock}
\begin{textblock}{8}(0.2,5.)
\begin{itemize}\itemsep=0cm\parskip=0cm
\item Low $S_{t}$ is good
\item Multiplier of 2 often omitted,\newline but useful for interpretation
\item $S_{t}$ like absolute error,\newline weighted to account for likely exceedance
\item Average $S_{t}(p,y)$ over $p$ = \newline CRPS (Continuous Rank Probability Score)
\end{itemize}
\end{textblock}
\placefig{8.7}{1.4}{width=7.3cm}{deciles.pdf}

\begin{textblock}{1}(8.5,5.1)
\animategraphics[loop,autoplay,width=7.4cm]{10}{Macquarie_2020_files/figure-beamer/pinball-}{1}{100}
\end{textblock}

## Evaluating probabilistic forecasts

### Continuous Rank Probability Score (univariate forecsts)

Forecast distribution $F_t$ and observation $y_t$.
$$
\text{CRPS}(F_t,y_t)~  = \int_{0}^1 S_{p,t}(p,y_t) dp ~  = ~\text{E}_F|Y-y_t|-\frac{1}{2}\text{E}_F|Y-Y^*|
$$

 * $Y$ and $Y^*$ are iid draws from $F_t$.
 * Optimal when $F_t$ is true distribution (i.e., it is a proper score)

\pause

### Energy score (multivariate forecasts)

 * $\text{ES}(F_t,\bm{y}_t) = \E_{F} ||{\bm{Y}}-\bm{y}_t|| -\frac{1}{2}\E_{F}||\bm{Y}-\bm{Y}^*||$

\pause

### Log score (multivariate forecasts)

 * $\text{LS}(F_t, \bm{y}_t) = -\log f(\bm{y}_t)$

## Evaluating probabilistic forecasts
\vspace*{-0.1cm}

\begin{alertblock}{Proper scoring rule}
optimized when true forecast distribution is used.
\end{alertblock}\pause\vspace*{-0.1cm}

\begin{block}{}\centering
\begin{tabular}{llp{4.4cm}}
    \bfseries Scoring Rule &
    \bfseries Coherent v Incoherent &
    \bfseries Coherent v Coherent\\
    \midrule
    Log Score & Not proper & $\bullet$ Ordering preserved\par\hspace*{0.3cm} if compared using\par\hspace*{0.3cm} bottom-level only\\
    Energy Score & Proper & $\bullet$ Full hierarchy\par\hspace*{0.3cm} should be used. \par $\bullet$ Rankings may\par\hspace*{0.3cm} change otherwise.
\end{tabular}
\end{block}


## To add from probabilistic paper

 * Score optimal reconciliation
 * Electricity example

# Example: Australian tourism

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r tourismdata, echo=TRUE}
tourism
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r tourismagg, echo=TRUE}
tourism_agg <- tourism %>%
  aggregate_key(state / zone / region, visitors = sum(visitors))
```

```{r tourismagg2, echo=FALSE}
tourism_agg
```


## Example: Australian tourism
\fontsize{10}{11}\sf

```{r tourismmodels, echo=TRUE}
fit <- tourism_agg %>%
  filter(year(month) <= 2015) %>%
  model(ets = ETS(visitors)) 
```

```{r tourismmodels1, echo=FALSE}
fit
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism, echo=TRUE}
fc <- fit %>%
  reconcile(ets_adjusted = min_trace(ets)) %>%
  forecast(h = "2 years")
```

```{r fctourism1, echo=FALSE}
fc
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism2, dependson='fctourism', echo=TRUE, fig.width=12, fig.height=4.5}
fc %>%
  filter(is_aggregated(state)) %>%
  autoplot(filter(tourism_agg, year(month) > 2012), level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism3, dependson='fctourism', echo=TRUE, fig.width=12, fig.height=4.5}
fc %>%
  filter(state == "NSW" & is_aggregated(zone)) %>%
  autoplot(filter(tourism_agg, year(month) > 2012), level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism4, dependson='fctourism', echo=TRUE, fig.width=12, fig.height=4.5}
fc %>%
  filter(region == "Melbourne") %>%
  autoplot(filter(tourism_agg, year(month) > 2012), level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism5, dependson='fctourism', echo=TRUE, fig.width=12, fig.height=4.5}
fc %>%
  filter(region == "Snowy Mountains") %>%
  autoplot(filter(tourism_agg, year(month) > 2012), level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism6, dependson='fctourism', echo=TRUE, fig.width=12, fig.height=4.5}
fc %>%
  filter(region == "Barossa") %>%
  autoplot(filter(tourism_agg, year(month) > 2012), level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism7, dependson='fctourism', echo=TRUE, fig.width=12, fig.height=4.5}
fc %>%
  filter(region == "MacDonnell") %>%
  autoplot(filter(tourism_agg, year(month) > 2012), level = 95)
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourismcomb, echo=TRUE}
fc <- tourism_agg %>%
  filter(year(month) <= 2015) %>%
  model(
    ets = ETS(visitors),
    arima = ARIMA(visitors)
  ) %>%
  mutate(
    comb = (ets + arima) / 2
  ) %>%
  reconcile(
    ets_adj = min_trace(ets),
    arima_adj = min_trace(arima),
    comb_adj = min_trace(comb)
  ) %>%
  forecast(h = "2 years")
```

## Forecast evaluation
\fontsize{10}{11}\sf

```{r fcaccuracy, dependson='fctourismcomb', echo=TRUE}
fc %>%  accuracy(
  data = tourism_agg,
    measures = list(crps = CRPS, ss=skill_score(CRPS))
  )
```

## Forecast evaluation
\fontsize{12}{13}\sf

```{r fcaccuracy2, dependson='fctourismcomb', echo=TRUE}
fc %>%
  tourism_agg,
    measures = list(crps = CRPS, ss=skill_score(CRPS))
  ) %>%
  group_by(.model) %>%
  summarise(sspc = mean(ss) * 100, mase = mean(MASE)) %>%
  arrange(sspc)
```

